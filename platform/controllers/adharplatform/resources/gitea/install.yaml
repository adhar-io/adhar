---
# Source: gitea/charts/postgresql/templates/primary/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: gitea-postgresql
  namespace: "adhar-system"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.14
    app.kubernetes.io/component: primary
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 5432
---
# Source: gitea/charts/postgresql/templates/primary/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gitea-postgresql
  namespace: "adhar-system"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.14
    app.kubernetes.io/component: primary
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
---
# Source: gitea/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitea-postgresql
  namespace: "adhar-system"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.14
automountServiceAccountToken: false
---
# Source: gitea/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-postgresql
  namespace: "adhar-system"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.14
type: Opaque
data:
  postgres-password: "NEtQdmVZOWViRw=="
  password: "Z2l0ZWE="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-inline-config
  namespace: adhar-system
  labels:
    helm.sh/chart: gitea-11.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.23.6"
    version: "1.23.6"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  _generals_: ""
  actions: ENABLED=false
  cache: |-
    ADAPTER=memory
    HOST=
  database: |-
    DB_TYPE=postgres
    HOST=gitea-postgresql.adhar-system.svc.cluster.local:5432
    NAME=gitea
    PASSWD=gitea
    USER=gitea
  indexer: ISSUE_INDEXER_TYPE=db
  metrics: ENABLED=false
  queue: |-
    CONN_STR=
    TYPE=level
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=adhar.localtest.me
    ENABLE_PPROF=false
    HTTP_ADDR=0.0.0.0
    HTTP_PORT=3000
    PROTOCOL=http
    ROOT_URL=https://adhar.localtest.me/gitea/
    SSH_DOMAIN=adhar.localtest.me
    SSH_LISTEN_PORT=2222
    SSH_PORT=22
    START_SSH_SERVER=true
  session: |-
    PROVIDER=memory
    PROVIDER_CONFIG=
---
# Source: gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea
  namespace: adhar-system
  labels:
    helm.sh/chart: gitea-11.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.23.6"
    version: "1.23.6"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  config_environment.sh: |
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi

      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "GITEA____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "GITEA__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::reload_preset_envs() {
      env2ini::log "Reloading preset envs..."

      while read -r line; do
        if [[ -z "${line}" ]]; then
          # skip empty line
          return
        fi

        # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
        local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

        if [[ -z "${setting}" ]]; then
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        local value=''
        local regex="^${setting}(\s*)=(\s*)(.*)"
        if [[ $line =~ $regex ]]; then
          value="${BASH_REMATCH[3]}"
        else
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        env2ini::log "  + '${setting}'"

        export "${setting^^}=${value}"                           # '^^' makes the variable content uppercase
      done < "$TMP_EXISTING_ENVS_FILE"

      rm $TMP_EXISTING_ENVS_FILE
    }


    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      if [[ -d "${path}" ]]; then
        env2ini::log "Processing $(basename "${path}")..."

        while read -d '' configFile; do
          env2ini::process_config_file "${configFile}"
        done < <(find "${path}" -type l -not -name '..data' -print0)

        env2ini::log "\n"
      fi
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export GITEA__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export GITEA__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export GITEA__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)
      export GITEA__SERVER__LFS_JWT_SECRET=$(gitea generate secret LFS_JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }

    # save existing envs prior to script execution. Necessary to keep order of preexisting and custom envs
    env | (grep -e '^GITEA__' || [[ $? == 1 ]]) > $TMP_EXISTING_ENVS_FILE

    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources "$ENV_TO_INI_MOUNT_POINT/inlines/"
    env2ini::load_config_sources "$ENV_TO_INI_MOUNT_POINT/additionals/"

    # load existing envs to override auto generated envs
    env2ini::reload_preset_envs

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'
      env2ini::log '  - server.LFS_JWT_SECRET'

      unset GITEA__SECURITY__INTERNAL_TOKEN
      unset GITEA__SECURITY__SECRET_KEY
      unset GITEA__OAUTH2__JWT_SECRET
      unset GITEA__SERVER__LFS_JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI
  assertions: |
---
# Source: gitea/templates/gitea/init.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-init
  namespace: adhar-system
  labels:
    helm.sh/chart: gitea-11.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.23.6"
    version: "1.23.6"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  configure_gpg_environment.sh: |
    #!/usr/bin/env bash
    set -eu

    gpg --batch --import "$TMP_RAW_GPG_KEY"
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail
    mkdir -pv /data/git/.ssh
    chmod -Rv 700 /data/git/.ssh
    [ ! -d /data/gitea/conf ] && mkdir -pv /data/gitea/conf

    # prepare temp directory structure
    mkdir -pv "${GITEA_TEMP}"
    chmod -v ug+rwx "${GITEA_TEMP}"

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    echo '==== BEGIN GITEA CONFIGURATION ===='

    retry=0
    max_retries=30
    until gitea migrate; do
      retry=$((retry+1))
      if [[ "${retry}" -ge "${max_retries}" ]]; then
        echo "Gitea migrate still failing after ${max_retries} attempts, giving up"
        exit 1
      fi
      echo "Gitea migrate failed (attempt ${retry}/${max_retries}). Waiting for database to be ready..."
      sleep 5
    done
    function configure_admin_user() {
      local full_admin_list=$(gitea admin user list --admin)
      local actual_user_table=''

      # We might have distorted output due to warning logs, so we have to detect the actual user table by its headline and trim output above that line
      local regex="(.*)(ID\s+Username\s+Email\s+IsActive.*)"
      if [[ "${full_admin_list}" =~ $regex ]]; then
        actual_user_table=$(echo "${BASH_REMATCH[2]}" | tail -n+2) # tail'ing to drop the table headline
      else
        # This code block should never be reached, as long as the output table header remains the same.
        # If this code block is reached, the regex doesn't match anymore and we probably have to adjust this script.

        echo "ERROR: 'configure_admin_user' was not able to determine the current list of admin users."
        echo "       Please review the output of 'gitea admin user list --admin' shown below."
        echo "       If you think it is an issue with the Helm Chart provisioning, file an issue at https://gitea.com/gitea/helm-gitea/issues."
        echo "DEBUG: Output of 'gitea admin user list --admin'"
        echo "--"
        echo "${full_admin_list}"
        echo "--"
        exit 1
      fi

      local ACCOUNT_ID=$(echo "${actual_user_table}" | grep -E "\s+${GITEA_ADMIN_USERNAME}\s+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        local -a create_args
        create_args=(--admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "gitea@local.domain")
        if [[ "${GITEA_ADMIN_PASSWORD_MODE}" = initialOnlyRequireReset ]]; then
          create_args+=(--must-change-password=true)
        else
          create_args+=(--must-change-password=false)
        fi
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create "${create_args[@]}"
        echo '...created.'
      else
        if [[ "${GITEA_ADMIN_PASSWORD_MODE}" = keepUpdated ]]; then
          echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
          # See https://gitea.com/gitea/helm-gitea/issues/673
          # --must-change-password argument was added to change-password, defaulting to true, counter to the previous behavior
          #   which acted as if it were provided with =false. If the argument is present in this version of gitea, then we
          #   should add it to prevent requiring frequent admin password resets.
          local -a change_args
          change_args=(--username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}")
          if gitea admin user change-password --help | grep -qF -- '--must-change-password'; then
            change_args+=(--must-change-password=false)
          fi
          gitea admin user change-password "${change_args[@]}"
          echo '...password sync done.'
        else
          echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist, but update mode is set to '${GITEA_ADMIN_PASSWORD_MODE}'. Skipping."
        fi
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END GITEA CONFIGURATION ===='
---
# Source: gitea/templates/gitea/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: gitea-shared-storage
  namespace: adhar-system
  annotations:
    helm.sh/resource-policy: keep
  labels: {}
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem

  resources:
    requests:
      storage: 10Gi
---
# Source: gitea/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-postgresql-hl
  namespace: "adhar-system"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.14
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: gitea/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-postgresql
  namespace: "adhar-system"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.14
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: gitea/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-http
  namespace: adhar-system
  labels:
    helm.sh/chart: gitea-11.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.23.6"
    version: "1.23.6"
    app.kubernetes.io/managed-by: Helm
  annotations: {}
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 3000
      targetPort: http
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
---
# Source: gitea/templates/gitea/ssh-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-ssh
  namespace: adhar-system
  labels:
    helm.sh/chart: gitea-11.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.23.6"
    version: "1.23.6"
    app.kubernetes.io/managed-by: Helm
  annotations: {}
spec:
  type: ClusterIP
  ports:
    - name: ssh
      port: 22
      targetPort: ssh
      protocol: TCP
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
---
# Source: gitea/templates/gitea/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gitea
  namespace: adhar-system
  annotations:
  labels:
    helm.sh/chart: gitea-11.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.23.6"
    version: "1.23.6"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 100%
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: gitea
  template:
    metadata:
      annotations:
        checksum/config: 2e55a90aebd849fba5ab7c6ad873da2beb1a8da489482b05479ba50a009a0a0d
      labels:
        helm.sh/chart: gitea-11.0.1
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: gitea
        app.kubernetes.io/version: "1.23.6"
        version: "1.23.6"
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: init-directories
          image: "docker.gitea.com/gitea:1.23.6-rootless"
          imagePullPolicy: IfNotPresent
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data

          securityContext: {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: init-app-ini
          image: "docker.gitea.com/gitea:1.23.6-rootless"
          imagePullPolicy: IfNotPresent
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: TMP_EXISTING_ENVS_FILE
              value: /tmp/existing-envs
            - name: ENV_TO_INI_MOUNT_POINT
              value: /env-to-ini-mounts
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/

          securityContext: {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: configure-gitea
          image: "docker.gitea.com/gitea:1.23.6-rootless"
          command: ["/usr/sbin/configure_gitea.sh"]
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: HOME
              value: /data/gitea/git
            - name: GITEA_ADMIN_USERNAME
              value: "gitea_admin"
            - name: GITEA_ADMIN_PASSWORD
              value: "r8sA8CPHD9!bt6d"
            - name: GITEA_ADMIN_PASSWORD_MODE
              value: keepUpdated
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data

          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
      terminationGracePeriodSeconds: 60
      containers:
        - name: gitea
          image: "docker.gitea.com/gitea:1.23.6-rootless"
          imagePullPolicy: IfNotPresent
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "2222"
            - name: SSH_PORT
              value: "22"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GOMAXPROCS
              valueFrom:
                resourceFieldRef:
                  divisor: "1"
                  resource: limits.cpu
            - name: TMPDIR
              value: /tmp/gitea
            - name: HOME
              value: /data/gitea/git
          ports:
            - name: ssh
              containerPort: 2222
            - name: http
              containerPort: 3000
          startupProbe:
            failureThreshold: 30
            periodSeconds: 10
            tcpSocket:
              port: http
            timeoutSeconds: 3
          livenessProbe:
            failureThreshold: 10
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 3
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 3
          resources:
            limits:
              cpu: 200m
              memory: 512Mi
            requests:
              cpu: 50m
              memory: 128Mi
          securityContext: {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data

      volumes:
        - name: init
          secret:
            secretName: gitea-init
            defaultMode: 110
        - name: config
          secret:
            secretName: gitea
            defaultMode: 110
        - name: inline-config-sources
          secret:
            secretName: gitea-inline-config
        - name: temp
          emptyDir: {}
        - name: data
          persistentVolumeClaim:
            claimName: gitea-shared-storage
---
# Source: gitea/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: gitea-postgresql
  namespace: "adhar-system"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.14
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: gitea-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: gitea-postgresql
      labels:
        app.kubernetes.io/instance: gitea
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 17.4.0
        helm.sh/chart: postgresql-16.4.14
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: gitea-postgresql

      automountServiceAccountToken: false
      affinity:
        podAffinity:

        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: gitea
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:

      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:latest
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "gitea"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gitea-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gitea-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "gitea"
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/conf
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/tmp
              subPath: app-tmp-dir
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "5Gi"
